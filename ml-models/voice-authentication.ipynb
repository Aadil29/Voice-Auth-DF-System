{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())         # should return True\n",
    "print(torch.cuda.get_device_name(0))     # should say \"NVIDIA GeForce RTX 3060\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# For data manipulation and analysis \n",
    "import pandas as pd\n",
    "\n",
    "# For numerical operations and array handling \n",
    "import numpy as np\n",
    "\n",
    "# For creating plots and visualisations\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# For advanced data visualisations \n",
    "import seaborn as sns\n",
    "\n",
    "# For file pattern matching \n",
    "import glob as glob\n",
    "\n",
    "# For audio processing \n",
    "import librosa\n",
    "\n",
    "# For displaying audio data visually \n",
    "import librosa.display\n",
    "\n",
    "# For playing audio directly in notebooks \n",
    "import IPython.display as ipd\n",
    "\n",
    "import wave\n",
    "\n",
    "#for reproduability \n",
    "import random\n",
    "\n",
    "#for the fodler re-structure 150 sample \n",
    "import shutil\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.join(os.getcwd(), 'datasets', 'voice-based-id-recognition')\n",
    "diffPhrase = os.path.join(base_dir,'differentPhrase')\n",
    "samePhrase = os.path.join(base_dir,'samePhrase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Dataset Location existance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differentPhrase Directory: \n",
      "['1', '10', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '11', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '12', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '13', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '14', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '15', '150', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99']\n",
      "samePhrase Directory: \n",
      "['1', '10', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '11', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '12', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '13', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '14', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '15', '150', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99']\n"
     ]
    }
   ],
   "source": [
    "# Check if the training directory exists\n",
    "if os.path.exists(diffPhrase):\n",
    "    print(\"differentPhrase Directory: \")\n",
    "    print(os.listdir(diffPhrase))\n",
    "else:\n",
    "    print(\"Directory does not exist:\", diffPhrase) \n",
    "   \n",
    "\n",
    "# Check if the testing directory exists\n",
    "if os.path.exists(samePhrase):\n",
    "    \n",
    "    print(\"samePhrase Directory: \")\n",
    "    print(os.listdir(samePhrase))\n",
    "else:\n",
    "    print(\"Directory does not exist:\", samePhrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listen to audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 18-19: truncated \\UXXXXXXXX escape (3963867248.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[31], line 22\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 18-19: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "file_path = r\"C:\\Users\\Aadil\\Desktop\\Voice-Auth-DF-System\\ml-models\\datasets\\voice-based-id-recognition\\differentPhrase\\1\\1-11.wav\"\n",
    "\n",
    "with wave.open(file_path, 'rb') as wav_file:\n",
    "    num_frames = wav_file.getnframes()\n",
    "    sample_rate = wav_file.getframerate()\n",
    "    sample_width = wav_file.getsampwidth()\n",
    "    channels = wav_file.getnchannels()\n",
    "    audio_data = wav_file.readframes(num_frames)\n",
    "\n",
    "# Convert raw bytes to numpy array\n",
    "audio_np = np.frombuffer(audio_data, dtype=np.int16)\n",
    "\n",
    "# If stereo, reshape\n",
    "if channels == 2:\n",
    "    audio_np = audio_np.reshape(-1, 2)\n",
    "\n",
    "ipd.Audio(audio_np, rate=sample_rate)\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aadil\\Desktop\\Voice-Auth-DF-System\\ml-models\\datasets\\vox1_dev\n",
      "Number of original Speakers :  1211\n",
      "Number of train Speakers :  150\n",
      "Number of test Speakers :  40\n"
     ]
    }
   ],
   "source": [
    "#Dataset split\n",
    "base_path = os.path.join(os.getcwd(), 'datasets', 'vox1_dev')\n",
    "print(base_path)\n",
    "\n",
    "#Each folder contains a different speaker\n",
    "\n",
    "speaker_count = sum(os.path.isdir(os.path.join(base_path, entry)) for entry in os.listdir(base_path))\n",
    "print(\"Number of original Speakers : \",speaker_count)\n",
    "#Select a random selection of speakers, as inital dataset of 1211 speakers is roughly 30GB. will take a sample of 150 speakers(12.3%), aroudn 3.7GB\n",
    "\n",
    "\"\"\"\"\n",
    "# Destination path for subset\n",
    "train_path = os.path.join(os.getcwd(), 'datasets', 'vox1_subset_150')\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "\n",
    "\n",
    "# Set seed and select random 150 speakers\n",
    "random.seed(42)\n",
    "all_speakers = [entry for entry in os.listdir(base_path)\n",
    "                if os.path.isdir(os.path.join(base_path, entry))]\n",
    "selected_speakers = random.sample(all_speakers, 150)\n",
    "\n",
    "# Copy selected speakers and their full contents to the subset folder\n",
    "for speaker in selected_speakers:\n",
    "    src_speaker_path = os.path.join(base_path, speaker)\n",
    "    dest_speaker_path = os.path.join(train_path, speaker)\n",
    "    shutil.copytree(src_speaker_path, dest_speaker_path)\n",
    "\n",
    "#print(f\"Subset dataset created at: {train_path}\")\n",
    "\"\"\"\n",
    "\n",
    "# Print the selected speaker folders\n",
    "count = 0\n",
    "#print(\"Selected speakers:\")\n",
    "for speaker in selected_speakers:\n",
    "    count +=1\n",
    "    #print(speaker)\n",
    "\n",
    "print(\"Number of train Speakers : \",count)\n",
    "\n",
    "\n",
    "\n",
    "test_path = os.path.join(os.getcwd(), 'datasets', 'vox1_subset_test')\n",
    "\n",
    "test_speaker_count = sum(os.path.isdir(os.path.join(test_path, entry)) for entry in os.listdir(test_path))\n",
    "print(\"Number of test Speakers : \",test_speaker_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing to see if files are copied in both train and test, tested using hash of the files to compare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55 common files.\n",
      "\n",
      "00001.wav - Different\n",
      "00002.wav - Different\n",
      "00003.wav - Different\n",
      "00004.wav - Different\n",
      "00005.wav - Different\n",
      "00006.wav - Different\n",
      "00007.wav - Different\n",
      "00008.wav - Different\n",
      "00009.wav - Different\n",
      "00010.wav - Different\n",
      "00011.wav - Different\n",
      "00012.wav - Different\n",
      "00013.wav - Different\n",
      "00014.wav - Different\n",
      "00015.wav - Different\n",
      "00016.wav - Different\n",
      "00017.wav - Different\n",
      "00018.wav - Different\n",
      "00019.wav - Different\n",
      "00020.wav - Different\n",
      "00021.wav - Different\n",
      "00022.wav - Different\n",
      "00023.wav - Different\n",
      "00024.wav - Different\n",
      "00025.wav - Different\n",
      "00026.wav - Different\n",
      "00027.wav - Different\n",
      "00028.wav - Different\n",
      "00029.wav - Different\n",
      "00030.wav - Different\n",
      "00031.wav - Different\n",
      "00032.wav - Different\n",
      "00033.wav - Different\n",
      "00034.wav - Different\n",
      "00035.wav - Different\n",
      "00036.wav - Different\n",
      "00037.wav - Different\n",
      "00038.wav - Different\n",
      "00039.wav - Different\n",
      "00040.wav - Different\n",
      "00041.wav - Different\n",
      "00042.wav - Different\n",
      "00043.wav - Different\n",
      "00044.wav - Different\n",
      "00045.wav - Different\n",
      "00046.wav - Different\n",
      "00047.wav - Different\n",
      "00048.wav - Different\n",
      "00049.wav - Different\n",
      "00050.wav - Different\n",
      "00051.wav - Different\n",
      "00052.wav - Different\n",
      "00053.wav - Different\n",
      "00054.wav - Different\n",
      "00055.wav - Different\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "\n",
    "def file_hash(filepath):\n",
    "    hasher = hashlib.sha256()\n",
    "    with open(filepath, 'rb') as f:\n",
    "        hasher.update(f.read())\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "# Define your paths\n",
    "test_path = os.path.join(os.getcwd(), 'datasets', 'vox1_subset_test')\n",
    "train_path = os.path.join(os.getcwd(), 'datasets', 'vox1_subset_150')\n",
    "\n",
    "# Map filenames to full paths\n",
    "def get_file_map(base_path):\n",
    "    file_map = {}\n",
    "    for root, _, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            file_map[file] = os.path.join(root, file)\n",
    "    return file_map\n",
    "\n",
    "test_files = get_file_map(test_path)\n",
    "train_files = get_file_map(train_path)\n",
    "\n",
    "# Compare common files\n",
    "common = set(test_files).intersection(train_files)\n",
    "print(f\"Found {len(common)} common files.\\n\")\n",
    "\n",
    "for filename in sorted(common):\n",
    "    test_file = test_files[filename]\n",
    "    train_file = train_files[filename]\n",
    "\n",
    "    same = file_hash(test_file) == file_hash(train_file)\n",
    "    print(f\"{filename} - {'Same' if same else 'Different'}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting train and validaion(80/20 split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! 120 speakers moved to train_data, 30 to val_data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Path to the dataset with 150 speaker folders\n",
    "source_path = os.path.join(os.getcwd(), 'datasets', 'vox1_subset_150')\n",
    "\n",
    "# Output subfolders for train and val\n",
    "train_folder = os.path.join(source_path, 'train_data')\n",
    "val_folder = os.path.join(source_path, 'val_data')\n",
    "\n",
    "# Create output folders if they don't exist\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(val_folder, exist_ok=True)\n",
    "\n",
    "# Get all speaker folders (exclude train_data and val_data if rerunning)\n",
    "speaker_folders = [folder for folder in os.listdir(source_path)\n",
    "                   if os.path.isdir(os.path.join(source_path, folder)) and folder not in ['train_data', 'val_data']]\n",
    "\n",
    "# Shuffle and split 80/20\n",
    "random.seed(42)\n",
    "random.shuffle(speaker_folders)\n",
    "split_index = int(0.8 * len(speaker_folders))\n",
    "train_speakers = speaker_folders[:split_index]\n",
    "val_speakers = speaker_folders[split_index:]\n",
    "\n",
    "# Copy folders to train_data\n",
    "for speaker in train_speakers:\n",
    "    src = os.path.join(source_path, speaker)\n",
    "    dst = os.path.join(train_folder, speaker)\n",
    "    shutil.move(src, dst)\n",
    "\n",
    "# Copy folders to val_data\n",
    "for speaker in val_speakers:\n",
    "    src = os.path.join(source_path, speaker)\n",
    "    dst = os.path.join(val_folder, speaker)\n",
    "    shutil.move(src, dst)\n",
    "\n",
    "print(f\"{len(train_speakers)} speakers moved to train_data, {len(val_speakers)} to val_data.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
