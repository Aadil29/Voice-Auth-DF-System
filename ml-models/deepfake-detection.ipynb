{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())         # should return True\n",
    "print(torch.cuda.get_device_name(0))     # should say \"NVIDIA GeForce RTX 3060\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data manipulation and analysis \n",
    "import pandas as pd\n",
    "\n",
    "# For numerical operations and array handling \n",
    "import numpy as np\n",
    "\n",
    "# For creating plots and visualisations\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# For advanced data visualisations \n",
    "#import seaborn as sns\n",
    "\n",
    "# For file pattern matching \n",
    "import glob as glob\n",
    "\n",
    "# For audio processing \n",
    "import librosa\n",
    "\n",
    "# For displaying audio data visually \n",
    "import librosa.display\n",
    "\n",
    "# For playing audio directly in notebooks \n",
    "import IPython.display as ipd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully split into train/val/test (70/15/15).\n",
      "Train files: 22245\n",
      "Val files: 4767\n",
      "Test files: 4767\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Config\n",
    "RANDOM_SEED = 42\n",
    "BASE_DIR = \"datasets/release_in_the_wild\"\n",
    "META_CSV = os.path.join(BASE_DIR, \"meta.csv\")\n",
    "WAV_DIR = BASE_DIR\n",
    "\n",
    "OUTPUT_DIRS = {\n",
    "    \"train\": os.path.join(BASE_DIR, \"train\"),\n",
    "    \"val\": os.path.join(BASE_DIR, \"val\"),\n",
    "    \"test\": os.path.join(BASE_DIR, \"test\")\n",
    "}\n",
    "\n",
    "# Create output folders\n",
    "for path in OUTPUT_DIRS.values():\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Load and clean metadata\n",
    "df = pd.read_csv(META_CSV, header=0)\n",
    "df[\"file\"] = df[\"file\"].str.strip()\n",
    "df[\"label\"] = df[\"label\"].str.strip()\n",
    "df[\"speaker\"] = df[\"speaker\"].str.strip()\n",
    "\n",
    "# Stratified 70/15/15 split\n",
    "train_df, temp_df = train_test_split(df, test_size=0.30, random_state=RANDOM_SEED, stratify=df[\"label\"])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=RANDOM_SEED, stratify=temp_df[\"label\"])\n",
    "\n",
    "# Move files\n",
    "def move_files(subset_df, split_name):\n",
    "    for _, row in subset_df.iterrows():\n",
    "        src = os.path.join(WAV_DIR, row[\"file\"])\n",
    "        dst = os.path.join(OUTPUT_DIRS[split_name], row[\"file\"])\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "move_files(train_df, \"train\")\n",
    "move_files(val_df, \"val\")\n",
    "move_files(test_df, \"test\")\n",
    "\n",
    "# Save metadata\n",
    "train_df.to_csv(os.path.join(BASE_DIR, \"train_meta.csv\"), index=False)\n",
    "val_df.to_csv(os.path.join(BASE_DIR, \"val_meta.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(BASE_DIR, \"test_meta.csv\"), index=False)\n",
    "\n",
    "print(\"Dataset successfully split into train/val/test (70/15/15).\")\n",
    "\n",
    "import os\n",
    "\n",
    "def count_files(folder_path):\n",
    "    return len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
    "\n",
    "# Example usage\n",
    "print(f\"Train files: {count_files('datasets/release_in_the_wild/train')}\")\n",
    "print(f\"Val files: {count_files('datasets/release_in_the_wild/val')}\")\n",
    "print(f\"Test files: {count_files('datasets/release_in_the_wild/test')}\")\n",
    "\n",
    "\n",
    "#files add up to the coprrect amout, so no fiels were lost in the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import noisereduce as nr\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "\n",
    "def preprocess_audio(y, sr, target_duration=6.0, apply_preemphasis=False, apply_reduction=False, coef=0.5, normalise='rms'):\n",
    "    \n",
    "    # Trim leading/trailing silence\n",
    "    y, _ = librosa.effects.trim(y)\n",
    "\n",
    "    # Apply noise reduction / dereverberation\n",
    "    if apply_reduction:\n",
    "        y = nr.reduce_noise(y=y, sr=sr)\n",
    "\n",
    "    # Apply pre-emphasis filter\n",
    "    if apply_preemphasis:\n",
    "        y = librosa.effects.preemphasis(y, coef=coef)\n",
    "\n",
    "    # Normalisation method\n",
    "    if normalise == 'rms':\n",
    "        rms = np.sqrt(np.mean(y**2))\n",
    "        y = y / (rms + 1e-6)\n",
    "    elif normalise == 'peak':\n",
    "        y = y / (np.max(np.abs(y)) + 1e-6)\n",
    "\n",
    "    # Duration control: pad or truncate\n",
    "    target_length = int(sr * target_duration)\n",
    "    if len(y) < target_length:\n",
    "        y = np.pad(y, (0, target_length - len(y)))\n",
    "    else:\n",
    "        y = y[:target_length]\n",
    "\n",
    "    return y\n",
    "\n",
    "def preprocess_folder(input_folder, output_folder, sr=22050, target_duration=6.0, apply_preemphasis=False, apply_reduction=False, coef=0.5, normalise='rms'):\n",
    "    \n",
    "    input_folder = Path(input_folder)\n",
    "    output_folder = Path(output_folder)\n",
    "    wav_files = list(input_folder.rglob(\"*.wav\"))\n",
    "    \n",
    "    print(f\"Found {len(wav_files)} audio files in {input_folder}\")\n",
    "\n",
    "    for wav_file in wav_files:\n",
    "        try:\n",
    "            y, _ = librosa.load(wav_file, sr=sr)\n",
    "            y = preprocess_audio(\n",
    "                y, sr, \n",
    "                target_duration=target_duration,\n",
    "                apply_preemphasis=apply_preemphasis,\n",
    "                apply_reduction=apply_reduction,\n",
    "                coef=coef,\n",
    "                normalise=normalise\n",
    "            )\n",
    "\n",
    "            # Save processed file to the same structure\n",
    "            relative_path = wav_file.relative_to(input_folder)\n",
    "            out_path = output_folder / relative_path\n",
    "            out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            sf.write(out_path, y, sr)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed: {wav_file} â†’ {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
